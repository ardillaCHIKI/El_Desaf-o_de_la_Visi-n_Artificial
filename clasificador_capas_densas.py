# Issue 4(F2): Capas Densas (Clasificador)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input

print("=" * 70)
print("ISSUE 4(F2): CAPAS DENSAS (CLASIFICADOR)")
print("=" * 70)

# ========== INICIALIZAR EL MODELO ==========
print("\nğŸ“¦ Inicializando modelo Sequential...")
model = Sequential(name="CNN_CIFAR10")

# AÃ±adir capa Input explÃ­cita
model.add(Input(shape=(32, 32, 3)))
print("âœ… Modelo creado con Input layer\n")

# ========== BLOQUES CONVOLUCIONALES (Issues anteriores) ==========
print("=" * 70)
print("AÃ‘ADIENDO BLOQUES CONVOLUCIONALES:")
print("=" * 70)

# Bloque 1
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', name='conv2d_1'))
model.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_1'))
print("âœ… Bloque 1: Conv2D(32) + MaxPooling aÃ±adido")

# Bloque 2
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', name='conv2d_2'))
model.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_2'))
print("âœ… Bloque 2: Conv2D(64) + MaxPooling aÃ±adido")

# ========== CAPAS DENSAS (NUEVO) ==========
print("\n" + "=" * 70)
print("AÃ‘ADIENDO CAPAS DENSAS (CLASIFICADOR):")
print("=" * 70)

# 1. Capa Flatten
print("\n1ï¸âƒ£ FLATTEN:")
model.add(Flatten(name='flatten'))
print("   âœ… Capa Flatten aÃ±adida")
print("   FunciÃ³n: Convierte mapas 2D en vector 1D")

# 2. Capa Dense oculta
print("\n2ï¸âƒ£ DENSE (Capa Oculta):")
model.add(Dense(64, activation='relu', name='dense_hidden'))
print("   âœ… Capa Dense con 64 neuronas y activaciÃ³n 'relu' aÃ±adida")
print("   FunciÃ³n: Aprendizaje de combinaciones no lineales")

# 3. Capa de salida
print("\n3ï¸âƒ£ DENSE (Capa de Salida):")
model.add(Dense(10, activation='softmax', name='dense_output'))
print("   âœ… Capa Dense con 10 neuronas y activaciÃ³n 'softmax' aÃ±adida")
print("   FunciÃ³n: ClasificaciÃ³n en 10 clases (probabilidades)")

# ========== CONSTRUIR EL MODELO ==========
model.build(input_shape=(None, 32, 32, 3))

# ========== RESUMEN DEL MODELO COMPLETO ==========
print("\n" + "=" * 70)
print("RESUMEN DEL MODELO COMPLETO:")
print("=" * 70)
model.summary()

# ========== ANÃLISIS DETALLADO DE DIMENSIONES ==========
print("\n" + "=" * 70)
print("ANÃLISIS DETALLADO DE DIMENSIONES:")
print("=" * 70)

input_tensor = model.inputs[0]
conv1_layer = model.layers[0]
pool1_layer = model.layers[1]
conv2_layer = model.layers[2]
pool2_layer = model.layers[3]
flatten_layer = model.layers[4]
dense_hidden = model.layers[5]
dense_output = model.layers[6]

print(f"""
TRANSFORMACIÃ“N COMPLETA DE DATOS:

1. INPUT (Imagen RGB):
   Shape: {input_tensor.shape}
   Tipo: Imagen 2D con 3 canales
   
2. Conv2D_1 (32 filtros, 3Ã—3):
   Shape: {conv1_layer.output.shape}
   
3. MaxPooling_1 (2Ã—2):
   Shape: {pool1_layer.output.shape}
   
4. Conv2D_2 (64 filtros, 3Ã—3):
   Shape: {conv2_layer.output.shape}
   
5. MaxPooling_2 (2Ã—2):
   Shape: {pool2_layer.output.shape}
   
6. ğŸ”„ FLATTEN (ConversiÃ³n 2D â†’ 1D):
   Shape: {flatten_layer.output.shape}
   CÃ¡lculo: 6 Ã— 6 Ã— 64 = {6*6*64} valores
   âš ï¸  PUNTO CRÃTICO: AquÃ­ pasamos de estructura espacial a vector
   
7. Dense_Hidden (64 neuronas, ReLU):
   Shape: {dense_hidden.output.shape}
   FunciÃ³n: Combinar features extraÃ­das
   
8. Dense_Output (10 neuronas, Softmax):
   Shape: {dense_output.output.shape}
   FunciÃ³n: Probabilidades de las 10 clases
""")

# ========== VERIFICACIONES AUTOMÃTICAS ==========
print("\n" + "=" * 70)
print("VERIFICACIONES AUTOMÃTICAS:")
print("=" * 70)

# Verificar nÃºmero total de capas
assert len(model.layers) == 7, f"âŒ Error: Se esperaban 7 capas, hay {len(model.layers)}"
print("âœ… El modelo tiene 7 capas (estructura completa)")

# Verificar tipos de capas
assert isinstance(flatten_layer, Flatten), "âŒ Error: Capa 4 no es Flatten"
assert isinstance(dense_hidden, Dense), "âŒ Error: Capa 5 no es Dense"
assert isinstance(dense_output, Dense), "âŒ Error: Capa 6 no es Dense"
print("âœ… Tipos de capas correctos (Flatten + 2 Dense)")

# Verificar dimensiones de salida
assert flatten_layer.output.shape == (None, 2304), f"âŒ Shape de Flatten incorrecta: {flatten_layer.output.shape}"
assert dense_hidden.output.shape == (None, 64), f"âŒ Shape de Dense_Hidden incorrecta: {dense_hidden.output.shape}"
assert dense_output.output.shape == (None, 10), f"âŒ Shape de Dense_Output incorrecta: {dense_output.output.shape}"
print("âœ… Output shapes correctos para todas las capas densas")

# Verificar activaciones
assert dense_hidden.activation.__name__ == 'relu', "âŒ Dense_Hidden debe usar 'relu'"
assert dense_output.activation.__name__ == 'softmax', "âŒ Dense_Output debe usar 'softmax'"
print("âœ… Funciones de activaciÃ³n correctas (relu y softmax)")

# Verificar nÃºmero de neuronas
assert dense_hidden.units == 64, f"âŒ Dense_Hidden debe tener 64 neuronas, tiene {dense_hidden.units}"
assert dense_output.units == 10, f"âŒ Dense_Output debe tener 10 neuronas, tiene {dense_output.units}"
print("âœ… NÃºmero de neuronas correcto (64 y 10)")

# ========== ANÃLISIS DE PARÃMETROS ==========
print("\n" + "=" * 70)
print("ANÃLISIS DE PARÃMETROS:")
print("=" * 70)

total_params = model.count_params()
conv1_params = conv1_layer.count_params()
conv2_params = conv2_layer.count_params()
dense_hidden_params = dense_hidden.count_params()
dense_output_params = dense_output.count_params()

print(f"""
DISTRIBUCIÃ“N DE PARÃMETROS:

Capas Convolucionales:
  â€¢ Conv2D_1 (32 filtros):     {conv1_params:>8,} parÃ¡metros
  â€¢ Conv2D_2 (64 filtros):     {conv2_params:>8,} parÃ¡metros
  â€¢ Subtotal Conv:             {conv1_params + conv2_params:>8,} parÃ¡metros

Capas Densas:
  â€¢ Dense_Hidden (64 units):   {dense_hidden_params:>8,} parÃ¡metros
  â€¢ Dense_Output (10 units):   {dense_output_params:>8,} parÃ¡metros
  â€¢ Subtotal Dense:            {dense_hidden_params + dense_output_params:>8,} parÃ¡metros

TOTAL:                         {total_params:>8,} parÃ¡metros

ğŸ’¡ ObservaciÃ³n: Las capas densas tienen MUCHOS mÃ¡s parÃ¡metros
   Dense_Hidden: 2304 Ã— 64 + 64 = {dense_hidden_params:,}
   Dense_Output: 64 Ã— 10 + 10 = {dense_output_params:,}
""")

# ========== VISUALIZACIÃ“N DE ARQUITECTURA COMPLETA ==========
print("\n" + "=" * 70)
print("ARQUITECTURA COMPLETA DEL MODELO:")
print("=" * 70)
print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT (32Ã—32Ã—3)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         EXTRACTOR DE CARACTERÃSTICAS          â•‘
    â•‘              (Capas Convolucionales)          â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                               â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘
    â•‘  â”‚ BLOQUE 1                            â”‚     â•‘
    â•‘  â”‚  â€¢ Conv2D(32, 3Ã—3) + ReLU           â”‚     â•‘
    â•‘  â”‚  â€¢ MaxPooling(2Ã—2)                  â”‚     â•‘
    â•‘  â”‚  â†’ Output: 15Ã—15Ã—32                 â”‚     â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘
    â•‘                    â†“                          â•‘
    â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â•‘
    â•‘  â”‚ BLOQUE 2                            â”‚     â•‘
    â•‘  â”‚  â€¢ Conv2D(64, 3Ã—3) + ReLU           â”‚     â•‘
    â•‘  â”‚  â€¢ MaxPooling(2Ã—2)                  â”‚     â•‘
    â•‘  â”‚  â†’ Output: 6Ã—6Ã—64                   â”‚     â•‘
    â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â•‘
    â•‘                                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          â†“
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘              CLASIFICADOR                     â•‘
    â•‘             (Capas Densas)                    â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                               â•‘
    â•‘  â€¢ Flatten: 6Ã—6Ã—64 â†’ 2304                     â•‘
    â•‘                    â†“                          â•‘
    â•‘  â€¢ Dense(64) + ReLU                           â•‘
    â•‘                    â†“                          â•‘
    â•‘  â€¢ Dense(10) + Softmax                        â•‘
    â•‘                                               â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           OUTPUT: Probabilidades (10 clases)            â”‚
â”‚    [P(aviÃ³n), P(auto), P(pÃ¡jaro), ..., P(camiÃ³n)]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ========== EXPLICACIÃ“N CONCEPTUAL ==========
print("\n" + "=" * 70)
print("ğŸ§  EXPLICACIÃ“N DE LAS CAPAS DENSAS:")
print("=" * 70)
print("""
1. Â¿POR QUÃ‰ FLATTEN?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Las capas convolucionales trabajan con datos 2D (mapas de caracterÃ­sticas)
   â€¢ Las capas Dense solo aceptan datos 1D (vectores)
   â€¢ Flatten "aplana" 6Ã—6Ã—64 = 2,304 valores en un vector largo
   
   Ejemplo visual:
   Antes:  [[[1,2], [3,4]], [[5,6], [7,8]]]  (estructura 2D)
   DespuÃ©s: [1, 2, 3, 4, 5, 6, 7, 8]          (vector 1D)

2. Â¿POR QUÃ‰ DENSE CON 64 NEURONAS?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Capa intermedia para combinar features extraÃ­das
   â€¢ 64 neuronas es suficiente para CIFAR-10 (no muy complejo)
   â€¢ ReLU aÃ±ade no-linealidad para aprender patrones complejos
   â€¢ ActÃºa como "integrador" de informaciÃ³n espacial

3. Â¿POR QUÃ‰ DENSE CON 10 NEURONAS Y SOFTMAX?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ 10 neuronas = 10 clases de CIFAR-10
   â€¢ Cada neurona representa una clase especÃ­fica
   â€¢ Softmax convierte scores en probabilidades que suman 1.0
   
   Ejemplo de salida:
   [0.7, 0.1, 0.05, 0.05, 0.02, 0.02, 0.02, 0.02, 0.01, 0.01]
    â†‘
   Clase 0 (aviÃ³n) tiene 70% de probabilidad

4. FLUJO DE INFORMACIÃ“N:
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ Bloques Conv: "Â¿QuÃ© features hay en la imagen?"
   â€¢ Flatten: "Convirtamos todo en un vector"
   â€¢ Dense(64): "Â¿CÃ³mo se combinan estas features?"
   â€¢ Dense(10): "Â¿A quÃ© clase pertenece?"

5. Â¿POR QUÃ‰ NO MÃS CAPAS DENSAS?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ CIFAR-10 es relativamente simple (10 clases, 32Ã—32)
   â€¢ MÃ¡s capas densas = mÃ¡s parÃ¡metros = riesgo de overfitting
   â€¢ Las capas Conv ya hicieron el trabajo pesado
   â€¢ Una capa Dense intermedia es suficiente
""")

# ========== CRITERIO DE ACEPTACIÃ“N ==========
print("\n" + "=" * 70)
print("CRITERIO DE ACEPTACIÃ“N - ISSUE 4(F2):")
print("=" * 70)
print("""
âœ… REQUISITOS CUMPLIDOS:

1. Capa Flatten:
   âœ“ AÃ±adida correctamente
   âœ“ Convierte (6, 6, 64) â†’ (2304,)

2. Capa Dense oculta:
   âœ“ 64 neuronas
   âœ“ ActivaciÃ³n 'relu'
   âœ“ ParÃ¡metros: 2304 Ã— 64 + 64 = 147,520

3. Capa de salida Dense:
   âœ“ 10 neuronas (una por clase)
   âœ“ ActivaciÃ³n 'softmax'
   âœ“ ParÃ¡metros: 64 Ã— 10 + 10 = 650

4. Resumen del modelo:
   âœ“ model.summary() muestra todas las capas
   âœ“ Dimensiones correctas en cada etapa
   âœ“ Total de parÃ¡metros calculado correctamente

5. Modelo completo y funcional:
   âœ“ 7 capas en total
   âœ“ Arquitectura: Input â†’ Conv â†’ Pool â†’ Conv â†’ Pool â†’ Flatten â†’ Dense â†’ Dense
   âœ“ Input shape: (32, 32, 3)
   âœ“ Output shape: (10,)
   âœ“ Listo para compilar y entrenar
""")

# ========== INFORMACIÃ“N ADICIONAL ==========
print("\n" + "=" * 70)
print("INFORMACIÃ“N ADICIONAL:")
print("=" * 70)
print(f"""
ğŸ“Š EstadÃ­sticas del Modelo:
   â€¢ Total de capas: {len(model.layers)}
   â€¢ Total de parÃ¡metros: {total_params:,}
   â€¢ Input shape: (32, 32, 3)
   â€¢ Output shape: (10,)
   
ğŸ¯ Clases CIFAR-10:
   0: airplane    5: dog
   1: automobile  6: frog
   2: bird        7: horse
   3: cat         8: ship
   4: deer        9: truck

ğŸ“ PrÃ³ximos pasos:
   1. Compilar el modelo (optimizer, loss, metrics)
   2. Preparar los datos (normalizaciÃ³n, one-hot)
   3. Entrenar con fit()
   4. Evaluar con evaluate()
   5. Hacer predicciones con predict()
""")

print("\n" + "=" * 70)
print("ISSUE 4(F2) COMPLETADO âœ…")
print("=" * 70)
print("\nğŸ¯ El modelo estÃ¡ COMPLETAMENTE construido y listo para compilar")
print("ğŸ“Š Arquitectura verificada y funcional")
print("ğŸš€ Â¡Listo para entrenar!")