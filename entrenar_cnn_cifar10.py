# Issue 2(F3): Entrenamiento del Modelo
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import numpy as np
import time

print("=" * 70)
print("ISSUE 2(F3): ENTRENAMIENTO DEL MODELO CNN")
print("=" * 70)

# ========== CARGAR Y PREPARAR LOS DATOS ==========
print("\nüìä PASO 1: CARGANDO Y PREPARANDO DATOS")
print("=" * 70)

# Cargar CIFAR-10
print("\nCargando dataset CIFAR-10...")
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print(f"‚úÖ Dataset cargado:")
print(f"   ‚Ä¢ x_train shape: {x_train.shape}")
print(f"   ‚Ä¢ y_train shape: {y_train.shape}")
print(f"   ‚Ä¢ x_test shape:  {x_test.shape}")
print(f"   ‚Ä¢ y_test shape:  {y_test.shape}")

# Normalizar las im√°genes (0-255 ‚Üí 0-1)
print("\nNormalizando im√°genes...")
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

print(f"‚úÖ Normalizaci√≥n completada:")
print(f"   ‚Ä¢ Rango de valores: [{x_train.min():.2f}, {x_train.max():.2f}]")
print(f"   ‚Ä¢ Media: {x_train.mean():.4f}")
print(f"   ‚Ä¢ Desviaci√≥n est√°ndar: {x_train.std():.4f}")

# Convertir etiquetas a one-hot encoding
print("\nConvirtiendo etiquetas a one-hot encoding...")
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

print(f"‚úÖ Conversi√≥n completada:")
print(f"   ‚Ä¢ y_train shape: {y_train.shape} (one-hot)")
print(f"   ‚Ä¢ y_test shape:  {y_test.shape} (one-hot)")

# Verificaciones finales de los datos
assert x_train.shape == (50000, 32, 32, 3), "‚ùå Error en shape de x_train"
assert y_train.shape == (50000, 10), "‚ùå Error en shape de y_train"
assert 0 <= x_train.min() <= x_train.max() <= 1, "‚ùå Error en normalizaci√≥n"

print("\n‚úÖ Datos preparados correctamente")

# ========== CONSTRUIR Y COMPILAR EL MODELO ==========
print("\n" + "=" * 70)
print("üèóÔ∏è  PASO 2: CONSTRUYENDO Y COMPILANDO EL MODELO")
print("=" * 70)

model = Sequential(name="CNN_CIFAR10")

# Arquitectura
model.add(Input(shape=(32, 32, 3)))
model.add(Conv2D(32, (3, 3), activation='relu', name='conv2d_1'))
model.add(MaxPooling2D((2, 2), name='maxpool_1'))
model.add(Conv2D(64, (3, 3), activation='relu', name='conv2d_2'))
model.add(MaxPooling2D((2, 2), name='maxpool_2'))
model.add(Flatten(name='flatten'))
model.add(Dense(64, activation='relu', name='dense_hidden'))
model.add(Dense(10, activation='softmax', name='dense_output'))

print("\n‚úÖ Modelo construido")

# Compilar
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("‚úÖ Modelo compilado")
print(f"   ‚Ä¢ Optimizador: Adam")
print(f"   ‚Ä¢ Loss: categorical_crossentropy")
print(f"   ‚Ä¢ M√©tricas: accuracy")

# Mostrar resumen
print("\n" + "-" * 70)
print("RESUMEN DEL MODELO:")
print("-" * 70)
model.summary()

# ========== CONFIGURAR PAR√ÅMETROS DE ENTRENAMIENTO ==========
print("\n" + "=" * 70)
print("‚öôÔ∏è  PASO 3: CONFIGURACI√ìN DE ENTRENAMIENTO")
print("=" * 70)

# Par√°metros
EPOCHS = 10
BATCH_SIZE = 64
VALIDATION_SPLIT = 0.1

print(f"""
Par√°metros de entrenamiento:
  ‚Ä¢ √âpocas (epochs):              {EPOCHS}
  ‚Ä¢ Tama√±o de batch (batch_size): {BATCH_SIZE}
  ‚Ä¢ Validaci√≥n (validation_split): {VALIDATION_SPLIT} ({VALIDATION_SPLIT*100:.0f}%)

Distribuci√≥n de datos:
  ‚Ä¢ Datos totales de entrenamiento: {len(x_train):,}
  ‚Ä¢ Datos para entrenamiento real:  {int(len(x_train) * (1-VALIDATION_SPLIT)):,} ({(1-VALIDATION_SPLIT)*100:.0f}%)
  ‚Ä¢ Datos para validaci√≥n:          {int(len(x_train) * VALIDATION_SPLIT):,} ({VALIDATION_SPLIT*100:.0f}%)
  ‚Ä¢ Datos de test (no se tocan):    {len(x_test):,}

Iteraciones por √©poca:
  ‚Ä¢ Batches por √©poca: {int(len(x_train) * (1-VALIDATION_SPLIT) / BATCH_SIZE)}
  ‚Ä¢ Iteraciones totales: {int(len(x_train) * (1-VALIDATION_SPLIT) / BATCH_SIZE) * EPOCHS}
""")

# ========== EXPLICACI√ìN DE PAR√ÅMETROS ==========
print("=" * 70)
print("üß† EXPLICACI√ìN DE PAR√ÅMETROS:")
print("=" * 70)

print("""
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ EPOCHS (√âpocas)                                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ¬øQu√© es una √©poca?                                            ‚îÇ
‚îÇ ‚Ä¢ Una pasada COMPLETA por todo el dataset de entrenamiento   ‚îÇ
‚îÇ ‚Ä¢ En cada √©poca, la red ve todas las 45,000 im√°genes         ‚îÇ
‚îÇ ‚Ä¢ Los pesos se actualizan m√∫ltiples veces por √©poca          ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ ¬øPor qu√© 10 √©pocas?                                           ‚îÇ
‚îÇ ‚Ä¢ Suficiente para ver mejora significativa                    ‚îÇ
‚îÇ ‚Ä¢ No tan largo que cause overfitting excesivo                 ‚îÇ
‚îÇ ‚Ä¢ Balance entre tiempo de entrenamiento y resultados          ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ Nota: Modelos profesionales usan 50-200 √©pocas, pero para    ‚îÇ
‚îÇ       pruebas iniciales, 10 es razonable.                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ BATCH_SIZE (Tama√±o de lote)                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ¬øQu√© es un batch?                                             ‚îÇ
‚îÇ ‚Ä¢ Grupo de im√°genes procesadas JUNTAS antes de actualizar    ‚îÇ
‚îÇ ‚Ä¢ Con batch_size=64: procesamos 64 im√°genes ‚Üí actualizamos   ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ ¬øPor qu√© 64?                                                  ‚îÇ
‚îÇ ‚Ä¢ Compromiso entre velocidad y estabilidad                    ‚îÇ
‚îÇ ‚Ä¢ Batch peque√±o (16): M√°s actualizaciones, m√°s ruido         ‚îÇ
‚îÇ ‚Ä¢ Batch grande (256): Menos actualizaciones, m√°s estable     ‚îÇ
‚îÇ ‚Ä¢ 64 es un valor est√°ndar que funciona bien                   ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ Valores t√≠picos:                                              ‚îÇ
‚îÇ ‚Ä¢ 32: Bueno para GPUs peque√±as                               ‚îÇ
‚îÇ ‚Ä¢ 64: ‚úÖ Valor por defecto recomendado                        ‚îÇ
‚îÇ ‚Ä¢ 128/256: Para GPUs potentes y datasets grandes             ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ Regla pr√°ctica: Usa potencias de 2 (32, 64, 128...)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VALIDATION_SPLIT (Divisi√≥n de validaci√≥n)                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ¬øQu√© es la validaci√≥n?                                        ‚îÇ
‚îÇ ‚Ä¢ Subset de datos NO usado para entrenar                      ‚îÇ
‚îÇ ‚Ä¢ Usado para evaluar durante el entrenamiento                ‚îÇ
‚îÇ ‚Ä¢ Permite detectar overfitting                                ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ ¬øPor qu√© 0.1 (10%)?                                           ‚îÇ
‚îÇ ‚Ä¢ 10% = 5,000 im√°genes para validaci√≥n                       ‚îÇ
‚îÇ ‚Ä¢ Suficiente para evaluar confiablemente                     ‚îÇ
‚îÇ ‚Ä¢ No resta demasiados datos al entrenamiento                 ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ Flujo de datos:                                               ‚îÇ
‚îÇ   50,000 im√°genes totales                                     ‚îÇ
‚îÇ   ‚îú‚îÄ 45,000 (90%) ‚Üí Entrenamiento (actualiza pesos)         ‚îÇ
‚îÇ   ‚îî‚îÄ  5,000 (10%) ‚Üí Validaci√≥n (solo eval√∫a)                ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ Diferencia con test:                                          ‚îÇ
‚îÇ ‚Ä¢ VALIDACI√ìN: Eval√∫a DURANTE entrenamiento                   ‚îÇ
‚îÇ ‚Ä¢ TEST: Eval√∫a DESPU√âS del entrenamiento                     ‚îÇ
‚îÇ ‚Ä¢ Test (10,000 imgs) NO se toca hasta el final               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
""")

# ========== ENTRENAR EL MODELO ==========
print("\n" + "=" * 70)
print("üöÄ PASO 4: ENTRENANDO EL MODELO")
print("=" * 70)

print(f"\nIniciando entrenamiento con {EPOCHS} √©pocas...")
print("‚è±Ô∏è  Esto puede tomar varios minutos...\n")

# Registrar tiempo de inicio
start_time = time.time()

# ENTRENAR
history = model.fit(
    x_train, 
    y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_split=VALIDATION_SPLIT,
    verbose=1  # Mostrar barra de progreso detallada
)

# Calcular tiempo total
end_time = time.time()
training_time = end_time - start_time

print("\n" + "=" * 70)
print("‚úÖ ENTRENAMIENTO COMPLETADO")
print("=" * 70)
print(f"‚è±Ô∏è  Tiempo total de entrenamiento: {training_time:.2f} segundos ({training_time/60:.2f} minutos)")
print(f"‚è±Ô∏è  Tiempo promedio por √©poca: {training_time/EPOCHS:.2f} segundos")

# ========== AN√ÅLISIS DEL HISTORIAL ==========
print("\n" + "=" * 70)
print("üìä PASO 5: AN√ÅLISIS DEL HISTORIAL DE ENTRENAMIENTO")
print("=" * 70)

# Extraer m√©tricas finales
final_train_loss = history.history['loss'][-1]
final_train_acc = history.history['accuracy'][-1]
final_val_loss = history.history['val_loss'][-1]
final_val_acc = history.history['val_accuracy'][-1]

print("\nüìà M√âTRICAS FINALES (√âpoca {}):\n".format(EPOCHS))
print(f"  ENTRENAMIENTO:")
print(f"    ‚Ä¢ Loss:     {final_train_loss:.4f}")
print(f"    ‚Ä¢ Accuracy: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)")
print(f"\n  VALIDACI√ìN:")
print(f"    ‚Ä¢ Loss:     {final_val_loss:.4f}")
print(f"    ‚Ä¢ Accuracy: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)")

# Detectar overfitting
overfitting_gap = final_train_acc - final_val_acc
print(f"\n  DIFERENCIA (Gap):")
print(f"    ‚Ä¢ Accuracy gap: {overfitting_gap:.4f} ({overfitting_gap*100:.2f}%)")

if overfitting_gap < 0.05:
    print("    ‚úÖ Bajo overfitting - Modelo generaliza bien")
elif overfitting_gap < 0.10:
    print("    ‚ö†Ô∏è  Overfitting moderado - Aceptable")
else:
    print("    ‚ùå Overfitting alto - Considerar regularizaci√≥n")

# ========== TABLA DE EVOLUCI√ìN POR √âPOCA ==========
print("\n" + "=" * 70)
print("üìã EVOLUCI√ìN DETALLADA POR √âPOCA:")
print("=" * 70)

print("\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
print("‚îÇ √âpoca ‚îÇ    ENTRENAMIENTO    ‚îÇ     VALIDACI√ìN      ‚îÇ")
print("‚îÇ       ‚îÇ  Loss    ‚îÇ Accuracy ‚îÇ  Loss    ‚îÇ Accuracy ‚îÇ")
print("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")

for epoch in range(EPOCHS):
    train_loss = history.history['loss'][epoch]
    train_acc = history.history['accuracy'][epoch]
    val_loss = history.history['val_loss'][epoch]
    val_acc = history.history['val_accuracy'][epoch]
    
    print(f"‚îÇ  {epoch+1:2d}   ‚îÇ  {train_loss:.4f}  ‚îÇ  {train_acc:.4f}  ‚îÇ  {val_loss:.4f}  ‚îÇ  {val_acc:.4f}  ‚îÇ")

print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")

# ========== AN√ÅLISIS DE MEJORA ==========
print("\n" + "=" * 70)
print("üìä AN√ÅLISIS DE MEJORA:")
print("=" * 70)

# Primera vs √∫ltima √©poca
first_train_acc = history.history['accuracy'][0]
first_val_acc = history.history['val_accuracy'][0]
train_improvement = (final_train_acc - first_train_acc) * 100
val_improvement = (final_val_acc - first_val_acc) * 100

print(f"""
PROGRESO DESDE LA PRIMERA √âPOCA:

Entrenamiento:
  ‚Ä¢ √âpoca 1:  {first_train_acc:.4f} ({first_train_acc*100:.2f}%)
  ‚Ä¢ √âpoca {EPOCHS}: {final_train_acc:.4f} ({final_train_acc*100:.2f}%)
  ‚Ä¢ Mejora:   +{train_improvement:.2f} puntos porcentuales

Validaci√≥n:
  ‚Ä¢ √âpoca 1:  {first_val_acc:.4f} ({first_val_acc*100:.2f}%)
  ‚Ä¢ √âpoca {EPOCHS}: {final_val_acc:.4f} ({final_val_acc*100:.2f}%)
  ‚Ä¢ Mejora:   +{val_improvement:.2f} puntos porcentuales

La red aprendi√≥ exitosamente ‚úÖ
""")

# ========== MEJOR √âPOCA ==========
best_epoch = np.argmax(history.history['val_accuracy']) + 1
best_val_acc = max(history.history['val_accuracy'])

print(f"""
MEJOR RENDIMIENTO EN VALIDACI√ìN:
  ‚Ä¢ √âpoca: {best_epoch}
  ‚Ä¢ Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)
""")

# ========== VERIFICACIONES FINALES ==========
print("=" * 70)
print("‚úÖ VERIFICACIONES FINALES:")
print("=" * 70)

# Verificar que history tiene las claves esperadas
expected_keys = ['loss', 'accuracy', 'val_loss', 'val_accuracy']
assert all(key in history.history for key in expected_keys), "‚ùå Faltan m√©tricas en history"
print("‚úÖ History contiene todas las m√©tricas esperadas")

# Verificar que se entrenaron todas las √©pocas
assert len(history.history['loss']) == EPOCHS, f"‚ùå Se esperaban {EPOCHS} √©pocas"
print(f"‚úÖ Se completaron todas las {EPOCHS} √©pocas")

# Verificar que la accuracy mejor√≥
assert final_val_acc > first_val_acc, "‚ùå La validaci√≥n no mejor√≥"
print("‚úÖ La accuracy de validaci√≥n mejor√≥ durante el entrenamiento")

# Verificar que el modelo aprendi√≥ algo √∫til
assert final_val_acc > 0.4, "‚ùå Accuracy muy baja, modelo no aprendi√≥"
print(f"‚úÖ Accuracy de validaci√≥n ({final_val_acc*100:.2f}%) es razonable")

# ========== INFORMACI√ìN DEL OBJETO HISTORY ==========
print("\n" + "=" * 70)
print("üìù INFORMACI√ìN DEL OBJETO HISTORY:")
print("=" * 70)

print(f"""
El objeto 'history' contiene:

history.history: diccionario con las m√©tricas
  ‚Ä¢ Keys: {list(history.history.keys())}
  
Cada key es una lista con valores por √©poca:
  ‚Ä¢ len(history.history['loss']): {len(history.history['loss'])} √©pocas
  
Acceso a datos:
  ‚Ä¢ history.history['loss'][0]          ‚Üí Loss de √©poca 1
  ‚Ä¢ history.history['val_accuracy'][-1] ‚Üí Val accuracy final
  ‚Ä¢ history.epoch                        ‚Üí Lista [0, 1, 2, ..., {EPOCHS-1}]

Este objeto es √∫til para:
  ‚úì Graficar curvas de aprendizaje
  ‚úì Detectar overfitting
  ‚úì Decidir early stopping
  ‚úì Comparar experimentos
""")

# ========== GUARDADO DEL HISTORIAL (OPCIONAL) ==========
print("\n" + "=" * 70)
print("üíæ GUARDADO DEL HISTORIAL (Opcional):")
print("=" * 70)

print("""
Para guardar el historial para an√°lisis posterior:

import pickle

# Guardar
with open('training_history.pkl', 'wb') as f:
    pickle.dump(history.history, f)

# Cargar m√°s tarde
with open('training_history.pkl', 'rb') as f:
    loaded_history = pickle.load(f)
""")

# ========== RESUMEN EJECUTIVO ==========
print("\n" + "=" * 70)
print("üìã RESUMEN EJECUTIVO:")
print("=" * 70)

print(f"""
ENTRENAMIENTO COMPLETADO EXITOSAMENTE ‚úÖ

Configuraci√≥n:
  ‚Ä¢ √âpocas: {EPOCHS}
  ‚Ä¢ Batch size: {BATCH_SIZE}
  ‚Ä¢ Validation split: {VALIDATION_SPLIT}
  
Resultados Finales:
  ‚Ä¢ Train Accuracy: {final_train_acc*100:.2f}%
  ‚Ä¢ Val Accuracy:   {final_val_acc*100:.2f}%
  ‚Ä¢ Mejora total:   +{val_improvement:.2f}%
  
Tiempo:
  ‚Ä¢ Total: {training_time/60:.2f} minutos
  ‚Ä¢ Por √©poca: {training_time/EPOCHS:.2f} segundos
  
Estado:
  ‚úÖ Modelo entrenado
  ‚úÖ M√©tricas generadas
  ‚úÖ History guardado en variable
  ‚úÖ Listo para evaluaci√≥n en test

Pr√≥ximos pasos:
  1. Evaluar en test set: model.evaluate(x_test, y_test)
  2. Graficar curvas de aprendizaje
  3. Analizar predicciones individuales
  4. Matriz de confusi√≥n
""")

print("\n" + "=" * 70)
print("ISSUE 2(F3) COMPLETADO ‚úÖ")
print("=" * 70)
print("\nüéâ ¬°Entrenamiento exitoso!")
print("üìä El modelo ha aprendido a clasificar im√°genes de CIFAR-10")
print("üöÄ Listo para evaluaci√≥n y an√°lisis de resultados")