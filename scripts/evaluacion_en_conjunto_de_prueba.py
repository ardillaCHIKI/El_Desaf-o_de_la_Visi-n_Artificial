# Issue 4(F3): EvaluaciÃ³n en Conjunto de Prueba
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import numpy as np

print("=" * 70)
print("ISSUE 4(F3): EVALUACIÃ“N EN CONJUNTO DE PRUEBA")
print("=" * 70)

# ========== PREPARAR DATOS Y ENTRENAR ==========
print("\nğŸ“Š PASO 1: PREPARANDO DATOS Y ENTRENANDO MODELO")
print("=" * 70)

print("\nCargando dataset CIFAR-10...")
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print("âœ… Dataset cargado")
print(f"   â€¢ Training set:   {len(x_train):,} imÃ¡genes")
print(f"   â€¢ Test set:       {len(x_test):,} imÃ¡genes")

# Normalizar
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Convertir a one-hot
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

print("âœ… Datos normalizados y convertidos a one-hot")

# Construir y compilar modelo
print("\nConstruyendo modelo...")
model = Sequential([
    Input(shape=(32, 32, 3)),
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
], name="CNN_CIFAR10")

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print("âœ… Modelo compilado")

# Entrenar
print("\nEntrenando modelo...")
history = model.fit(
    x_train, y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.1,
    verbose=0
)
print("âœ… Entrenamiento completado\n")

# MÃ©tricas de validaciÃ³n
val_acc = history.history['val_accuracy'][-1]
val_loss = history.history['val_loss'][-1]

print(f"Resultados finales de VALIDACIÃ“N:")
print(f"  â€¢ Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)")
print(f"  â€¢ Loss:     {val_loss:.4f}")

# ========== EVALUACIÃ“N EN TEST SET ==========
print("\n" + "=" * 70)
print("ğŸ§ª PASO 2: EVALUACIÃ“N EN CONJUNTO DE PRUEBA")
print("=" * 70)

print("\nâš ï¸  IMPORTANTE:")
print("   El conjunto de test NO se ha usado durante el entrenamiento.")
print("   Representa datos completamente nuevos para el modelo.")
print("   Esta es la evaluaciÃ³n MÃS REALISTA del rendimiento.\n")

print("Evaluando modelo en test set...")
print("(Esto puede tomar unos segundos...)\n")

# EVALUAR EN TEST
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)

print("\n" + "=" * 70)
print("ğŸ“Š RESULTADOS EN CONJUNTO DE PRUEBA:")
print("=" * 70)

print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              RESULTADOS FINALES EN TEST SET                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘  Test Loss:     {test_loss:6.4f}                                    â•‘
â•‘  Test Accuracy: {test_accuracy:6.4f}  ({test_accuracy*100:5.2f}%)                      â•‘
â•‘                                                            â•‘
â•‘  ImÃ¡genes evaluadas: {len(x_test):,}                              â•‘
â•‘  Predicciones correctas: {int(test_accuracy * len(x_test)):,}                      â•‘
â•‘  Predicciones incorrectas: {int((1 - test_accuracy) * len(x_test)):,}                    â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# ========== COMPARACIÃ“N VALIDACIÃ“N VS TEST ==========
print("\n" + "=" * 70)
print("ğŸ“Š COMPARACIÃ“N: VALIDACIÃ“N vs TEST")
print("=" * 70)

# Calcular diferencias
acc_diff = val_acc - test_accuracy
loss_diff = test_loss - val_loss

print(f"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚  VALIDACIÃ“N  â”‚     TEST     â”‚  DIFERENCIA â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Accuracy        â”‚   {val_acc:.4f}     â”‚   {test_accuracy:.4f}     â”‚   {acc_diff:+.4f}    â”‚
â”‚ Loss            â”‚   {val_loss:.4f}     â”‚   {test_loss:.4f}     â”‚   {loss_diff:+.4f}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Porcentajes:
  â€¢ ValidaciÃ³n: {val_acc*100:.2f}%
  â€¢ Test:       {test_accuracy*100:.2f}%
  â€¢ Diferencia: {acc_diff*100:+.2f}%
""")

# ========== INTERPRETACIÃ“N DE LA DIFERENCIA ==========
print("\n" + "=" * 70)
print("ğŸ” INTERPRETACIÃ“N DE LA DIFERENCIA:")
print("=" * 70)

print("\nÂ¿QuÃ© significa esta diferencia?\n")

if abs(acc_diff) < 0.02:
    interpretation = "âœ… EXCELENTE"
    explanation = """
    La diferencia es MÃNIMA (< 2%).
    
    Esto significa:
    â€¢ El modelo generaliza MUY BIEN
    â€¢ No hay overfitting significativo al conjunto de validaciÃ³n
    â€¢ El conjunto de validaciÃ³n fue representativo
    â€¢ El rendimiento es consistente entre conjuntos
    
    ConclusiÃ³n: Modelo muy robusto y confiable."""
    
elif abs(acc_diff) < 0.05:
    interpretation = "âœ… BUENO"
    explanation = """
    La diferencia es PEQUEÃ‘A (2-5%).
    
    Esto significa:
    â€¢ El modelo generaliza BIEN
    â€¢ Overfitting mÃ­nimo
    â€¢ Comportamiento esperado y normal
    â€¢ El conjunto de validaciÃ³n fue razonablemente representativo
    
    ConclusiÃ³n: Modelo confiable con buen equilibrio."""
    
elif abs(acc_diff) < 0.10:
    interpretation = "âš ï¸  ACEPTABLE"
    explanation = """
    La diferencia es MODERADA (5-10%).
    
    Esto puede indicar:
    â€¢ Ligero overfitting al conjunto de validaciÃ³n
    â€¢ O variabilidad natural entre subconjuntos
    â€¢ El modelo es razonablemente robusto
    
    ConclusiÃ³n: Modelo funcional pero con margen de mejora."""
    
else:
    interpretation = "ğŸ”´ PREOCUPANTE"
    explanation = """
    La diferencia es GRANDE (> 10%).
    
    Esto indica:
    â€¢ Overfitting significativo
    â€¢ El conjunto de validaciÃ³n no fue representativo
    â€¢ O el modelo es inestable
    
    ConclusiÃ³n: Requiere ajustes (regularizaciÃ³n, mÃ¡s datos, etc.)."""

print(f"Estado: {interpretation}")
print(f"Diferencia de accuracy: {acc_diff*100:+.2f}%")
print(explanation)

# ========== ANÃLISIS ADICIONAL: DIRECCIÃ“N DE LA DIFERENCIA ==========
print("\n" + "-" * 70)
print("ANÃLISIS DE DIRECCIÃ“N:")
print("-" * 70)

if acc_diff > 0:
    print(f"""
ValidaciÃ³n ({val_acc*100:.2f}%) > Test ({test_accuracy*100:.2f}%)

Posibles razones:
1. OVERFITTING: El modelo se ajustÃ³ ligeramente al conjunto de validaciÃ³n
   â€¢ Aunque no entrenamos directamente con validaciÃ³n, podrÃ­amos 
     haber hecho ajustes (implÃ­citos o explÃ­citos) basados en val_accuracy

2. VARIABILIDAD ALEATORIA: Los conjuntos son muestras aleatorias
   â€¢ Es normal cierta variaciÃ³n entre subconjuntos
   â€¢ Si la diferencia es < 5%, es completamente normal

3. DISTRIBUCIÃ“N: El test set podrÃ­a tener ejemplos mÃ¡s difÃ­ciles
   â€¢ CIFAR-10 tiene imÃ¡genes de diferentes dificultades
   â€¢ Mala suerte en la particiÃ³n aleatoria

EvaluaciÃ³n: {'Normal si < 5%' if acc_diff < 0.05 else 'Considerar overfitting'}
""")
else:
    print(f"""
Test ({test_accuracy*100:.2f}%) > ValidaciÃ³n ({val_acc*100:.2f}%)

Posibles razones:
1. BUENA SUERTE: El test set tiene ejemplos mÃ¡s fÃ¡ciles
   â€¢ VariaciÃ³n aleatoria favorable

2. VALIDACIÃ“N MÃS DIFÃCIL: El 10% de validaciÃ³n era mÃ¡s desafiante
   â€¢ Puede pasar con conjuntos pequeÃ±os

3. MODELO ROBUSTO: Generaliza incluso mejor de lo esperado
   â€¢ SeÃ±al positiva de buena arquitectura

EvaluaciÃ³n: âœ… SituaciÃ³n favorable, pero inusual
""")

# ========== CONTEXTO PARA CIFAR-10 ==========
print("\n" + "=" * 70)
print("ğŸ“š CONTEXTO: RENDIMIENTO TÃPICO EN CIFAR-10")
print("=" * 70)

print(f"""
Benchmarks de accuracy en CIFAR-10:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tipo de Modelo              â”‚  Accuracy    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Random Guess (baseline)     â”‚    10%       â”‚
â”‚ Shallow MLP                 â”‚    40-50%    â”‚
â”‚ CNN Simple (nuestra)        â”‚  âœ“ 60-75%    â”‚ â† Nuestro rango esperado
â”‚ CNN con Data Augmentation   â”‚    75-85%    â”‚
â”‚ ResNet-18                   â”‚    85-90%    â”‚
â”‚ ResNet-50                   â”‚    90-93%    â”‚
â”‚ State-of-the-art (2024)     â”‚    99%+      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Tu modelo: {test_accuracy*100:.2f}%
""")

# ClasificaciÃ³n del rendimiento
if test_accuracy >= 0.75:
    performance = "ğŸŒŸ EXCELENTE"
    comment = "Muy por encima del baseline para una CNN simple"
elif test_accuracy >= 0.65:
    performance = "âœ… BUENO"
    comment = "Dentro del rango esperado para esta arquitectura"
elif test_accuracy >= 0.55:
    performance = "âš ï¸  ACEPTABLE"
    comment = "Por debajo del Ã³ptimo, hay margen de mejora"
else:
    performance = "ğŸ”´ BAJO"
    comment = "Significativamente por debajo de lo esperado"

print(f"\nRendimiento: {performance}")
print(f"EvaluaciÃ³n: {comment}")

# ========== ANÃLISIS DE ERRORES ==========
print("\n" + "=" * 70)
print("ğŸ” ANÃLISIS DE ERRORES:")
print("=" * 70)

correct_predictions = int(test_accuracy * len(x_test))
incorrect_predictions = len(x_test) - correct_predictions

print(f"""
De {len(x_test):,} imÃ¡genes de test:

âœ… CORRECTAS:   {correct_predictions:,} ({test_accuracy*100:.2f}%)
âŒ INCORRECTAS: {incorrect_predictions:,} ({(1-test_accuracy)*100:.2f}%)

Tasa de error: {(1-test_accuracy)*100:.2f}%

Esto significa:
  â€¢ De cada 100 imÃ¡genes, el modelo clasifica correctamente ~{int(test_accuracy*100)}
  â€¢ De cada 100 imÃ¡genes, el modelo se equivoca en ~{int((1-test_accuracy)*100)}
""")

# ========== POSIBLES MEJORAS ==========
print("\n" + "=" * 70)
print("ğŸ’¡ POSIBLES MEJORAS AL MODELO:")
print("=" * 70)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£  ARQUITECTURA                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚ âœ“ AÃ±adir mÃ¡s capas convolucionales (3-4 bloques total)       â”‚
â”‚     model.add(Conv2D(128, (3,3), activation='relu'))         â”‚
â”‚     model.add(MaxPooling2D((2,2)))                           â”‚
â”‚                                                                â”‚
â”‚ âœ“ Aumentar nÃºmero de filtros progresivamente                  â”‚
â”‚     32 â†’ 64 â†’ 128 â†’ 256                                       â”‚
â”‚                                                                â”‚
â”‚ âœ“ Usar Batch Normalization                                    â”‚
â”‚     model.add(BatchNormalization())                           â”‚
â”‚     Acelera entrenamiento y mejora estabilidad                â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£  REGULARIZACIÃ“N                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚ âœ“ AÃ±adir Dropout para reducir overfitting                     â”‚
â”‚     model.add(Dropout(0.3))                                   â”‚
â”‚     model.add(Dropout(0.5))  # Antes de Ãºltima capa          â”‚
â”‚                                                                â”‚
â”‚ âœ“ Usar regularizaciÃ³n L2                                      â”‚
â”‚     Dense(64, kernel_regularizer=l2(0.001))                   â”‚
â”‚                                                                â”‚
â”‚ âœ“ Early Stopping                                              â”‚
â”‚     EarlyStopping(patience=5, restore_best_weights=True)      â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£  DATA AUGMENTATION                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚ âœ“ Aumentar artificialmente el dataset                         â”‚
â”‚     datagen = ImageDataGenerator(                             â”‚
â”‚         rotation_range=15,                                    â”‚
â”‚         width_shift_range=0.1,                                â”‚
â”‚         height_shift_range=0.1,                               â”‚
â”‚         horizontal_flip=True                                  â”‚
â”‚     )                                                          â”‚
â”‚                                                                â”‚
â”‚ Impacto esperado: +5-10% accuracy                             â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4ï¸âƒ£  HIPERPARÃMETROS                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚ âœ“ Ajustar learning rate                                       â”‚
â”‚     optimizer=Adam(learning_rate=0.0001)  # MÃ¡s conservador  â”‚
â”‚                                                                â”‚
â”‚ âœ“ Usar learning rate scheduler                                â”‚
â”‚     ReduceLROnPlateau(factor=0.5, patience=3)                 â”‚
â”‚                                                                â”‚
â”‚ âœ“ Entrenar mÃ¡s Ã©pocas (20-50)                                 â”‚
â”‚                                                                â”‚
â”‚ âœ“ Probar diferentes batch sizes (32, 128)                     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5ï¸âƒ£  TÃ‰CNICAS AVANZADAS                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚ âœ“ Transfer Learning (usar modelo pre-entrenado)               â”‚
â”‚     VGG16, ResNet50, EfficientNet                             â”‚
â”‚                                                                â”‚
â”‚ âœ“ Ensemble de modelos                                         â”‚
â”‚     Combinar predicciones de varios modelos                   â”‚
â”‚                                                                â”‚
â”‚ âœ“ Test-Time Augmentation (TTA)                                â”‚
â”‚     Predecir sobre versiones aumentadas y promediar           â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ========== PRIORIZACIÃ“N DE MEJORAS ==========
print("\n" + "=" * 70)
print("ğŸ¯ PRIORIZACIÃ“N DE MEJORAS:")
print("=" * 70)

if test_accuracy < 0.60:
    priority = """
    PRIORIDAD ALTA (Modelo necesita mejoras sustanciales):
    
    1. ğŸ”´ CRÃTICO: Revisar arquitectura
       â€¢ AÃ±adir mÃ¡s capas convolucionales
       â€¢ Aumentar nÃºmero de filtros
       
    2. ğŸ”´ CRÃTICO: Verificar datos
       â€¢ Asegurar normalizaciÃ³n correcta
       â€¢ Verificar one-hot encoding
       
    3. ğŸŸ¡ IMPORTANTE: Entrenar mÃ¡s tiempo
       â€¢ Aumentar a 20-30 Ã©pocas
       â€¢ Monitorear curvas de aprendizaje
    """
elif test_accuracy < 0.70:
    priority = """
    PRIORIDAD MEDIA (Modelo funciona pero tiene margen):
    
    1. ğŸŸ¡ RECOMENDADO: Data Augmentation
       â€¢ Impacto: +5-10% accuracy
       â€¢ ImplementaciÃ³n simple
       
    2. ğŸŸ¡ RECOMENDADO: RegularizaciÃ³n
       â€¢ AÃ±adir Dropout(0.3, 0.5)
       â€¢ Ayuda con overfitting
       
    3. ğŸŸ¢ OPCIONAL: MÃ¡s capas
       â€¢ Un tercer bloque convolucional
       â€¢ Conv2D(128) + MaxPooling
    """
else:
    priority = """
    PRIORIDAD BAJA (Modelo funciona bien):
    
    1. ğŸŸ¢ OPCIONAL: Fine-tuning
       â€¢ Ajustar learning rate
       â€¢ Experimentar con batch size
       
    2. ğŸŸ¢ OPCIONAL: TÃ©cnicas avanzadas
       â€¢ Batch Normalization
       â€¢ Learning rate scheduling
       
    3. ğŸ”µ EXPLORACIÃ“N: Transfer Learning
       â€¢ Solo si necesitas > 85% accuracy
    """

print(priority)

# ========== CONCLUSIONES FINALES ==========
print("\n" + "=" * 70)
print("ğŸ“‹ CONCLUSIONES FINALES:")
print("=" * 70)

# Generar conclusiÃ³n personalizada
if test_accuracy >= 0.70:
    conclusion_quality = "âœ… EXITOSO"
    conclusion_text = f"""
El modelo ha alcanzado una accuracy de {test_accuracy*100:.2f}% en el test set,
lo cual es un resultado BUENO para una CNN simple en CIFAR-10.

Logros:
â€¢ SuperÃ³ el baseline de CNNs simples (~60%)
â€¢ Generaliza bien a datos nuevos
â€¢ Diferencia validaciÃ³n-test aceptable: {abs(acc_diff)*100:.2f}%

El modelo estÃ¡ listo para uso en aplicaciones reales, aunque
mejoras adicionales podrÃ­an aumentar su rendimiento.
    """
elif test_accuracy >= 0.60:
    conclusion_quality = "âœ… ACEPTABLE"
    conclusion_text = f"""
El modelo ha alcanzado una accuracy de {test_accuracy*100:.2f}% en el test set,
lo cual estÃ¡ en el rango esperado para una CNN simple en CIFAR-10.

Logros:
â€¢ Supera ampliamente el random guess (10%)
â€¢ EstÃ¡ en el rango tÃ­pico (60-75%)
â€¢ Demuestra que la arquitectura CNN funciona

Con las mejoras sugeridas (Data Augmentation, Dropout, mÃ¡s capas),
se podrÃ­a alcanzar fÃ¡cilmente 75-80% de accuracy.
    """
else:
    conclusion_quality = "âš ï¸  MEJORABLE"
    conclusion_text = f"""
El modelo ha alcanzado una accuracy de {test_accuracy*100:.2f}% en el test set,
lo cual estÃ¡ por debajo del rendimiento tÃ­pico para CNNs en CIFAR-10.

Observaciones:
â€¢ Hay margen significativo de mejora
â€¢ La arquitectura necesita refinamiento
â€¢ Considerar aumentar capacidad del modelo

RecomendaciÃ³n: Implementar las mejoras prioritarias mencionadas,
especialmente aÃ±adir mÃ¡s capas convolucionales y usar Data Augmentation.
    """

print(f"\n{conclusion_quality}\n")
print(conclusion_text)

# ========== RESUMEN EJECUTIVO FINAL ==========
print("\n" + "=" * 70)
print("ğŸ“Š RESUMEN EJECUTIVO:")
print("=" * 70)

print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   EVALUACIÃ“N FINAL                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                            â•‘
â•‘  Test Accuracy:      {test_accuracy*100:5.2f}%                             â•‘
â•‘  Test Loss:          {test_loss:6.4f}                                â•‘
â•‘                                                            â•‘
â•‘  ValidaciÃ³n Accuracy: {val_acc*100:5.2f}%                            â•‘
â•‘  Diferencia Val-Test: {acc_diff*100:+5.2f}%                            â•‘
â•‘                                                            â•‘
â•‘  ImÃ¡genes correctas:  {correct_predictions:,} / {len(x_test):,}                   â•‘
â•‘  Tasa de error:       {(1-test_accuracy)*100:5.2f}%                             â•‘
â•‘                                                            â•‘
â•‘  Rendimiento:         {performance:20s}            â•‘
â•‘  GeneralizaciÃ³n:      {interpretation:20s}            â•‘
â•‘                                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ESTADO: âœ… EvaluaciÃ³n completada exitosamente

PRÃ“XIMOS PASOS SUGERIDOS:
  1. Analizar matriz de confusiÃ³n (Â¿quÃ© clases confunde?)
  2. Visualizar predicciones incorrectas
  3. Implementar mejoras prioritarias
  4. Re-entrenar y comparar resultados
""")

print("\n" + "=" * 70)
print("ISSUE 4(F3) COMPLETADO âœ…")
print("=" * 70)
print("\nğŸ¯ EvaluaciÃ³n en test set completada")
print("ğŸ“Š Capacidad de generalizaciÃ³n medida")
print("ğŸ’¡ Recomendaciones de mejora proporcionadas")
print("âœ… Modelo listo para anÃ¡lisis detallado o despliegue")