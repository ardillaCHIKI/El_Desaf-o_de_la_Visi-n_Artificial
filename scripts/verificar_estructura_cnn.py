# Issue 5: Confirmar Estructura 2D del Dataset
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10

# Cargar el dataset
(x_train, y_train), (_, _) = cifar10.load_data()

# ========== VERIFICACIONES DE ESTRUCTURA 2D ==========
print("=" * 60)
print("VERIFICACI√ìN DE ESTRUCTURA 2D - ISSUE 5")
print("=" * 60)

# 1. Verificar forma del DATASET COMPLETO (no solo una imagen)
print(f"\nForma del dataset completo: {x_train.shape}")
print(f"  ‚Üí {x_train.shape[0]} im√°genes")
print(f"  ‚Üí Cada imagen: {x_train.shape[1]}x{x_train.shape[2]} p√≠xeles")
print(f"  ‚Üí {x_train.shape[3]} canales RGB")

# 2. Verificar una imagen individual
ejemplo = x_train[0]
print(f"\nForma de UNA imagen: {ejemplo.shape}")
print(f"N√∫mero de dimensiones: {ejemplo.ndim}D")

# 3. VERIFICACI√ìN CR√çTICA: Asegurar que NO est√° aplanada
assert ejemplo.shape == (32, 32, 3), "‚ùå ERROR: La imagen no tiene estructura 2D"
assert x_train.ndim == 4, "‚ùå ERROR: El dataset no mantiene estructura 2D"
print("\n‚úÖ VERIFICACI√ìN EXITOSA: Estructura 2D preservada")

# Mostrar la imagen
plt.figure(figsize=(6, 6))
plt.imshow(ejemplo)
plt.title(f"Ejemplo de clase: {y_train[0][0]} - Forma: {ejemplo.shape}")
plt.axis('off')
plt.savefig('verificacion_estructura_2d.png', dpi=150, bbox_inches='tight')
plt.show()

# Guardar la imagen para pruebas futuras
np.save("imagen_ejemplo_cnn.npy", ejemplo)
print("\n‚úÖ Imagen guardada como 'imagen_ejemplo_cnn.npy'")

# ========== COMPARACI√ìN VISUAL MLP vs CNN ==========
print("\n" + "=" * 60)
print("COMPARACI√ìN: MLP vs CNN")
print("=" * 60)

# Mostrar c√≥mo se ver√≠a aplanada (para MLP) vs 2D (para CNN)
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# CNN: Estructura 2D
axes[0].imshow(ejemplo)
axes[0].set_title(f'‚úÖ PARA CNN\nEstructura 2D: {ejemplo.shape}', 
                  fontsize=12, weight='bold', color='green')
axes[0].axis('off')

# MLP: Estructura 1D (visualizaci√≥n)
ejemplo_plano = ejemplo.flatten()
axes[1].plot(ejemplo_plano[:500], linewidth=0.8, color='red')
axes[1].set_title(f'‚ùå PARA MLP (NO usar aqu√≠)\nEstructura 1D: {ejemplo_plano.shape}', 
                  fontsize=12, weight='bold', color='red')
axes[1].set_xlabel('√çndice del p√≠xel')
axes[1].set_ylabel('Valor del p√≠xel')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('comparacion_mlp_vs_cnn.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"\nüìä Comparaci√≥n visual guardada como 'comparacion_mlp_vs_cnn.png'")

# ========== COMENTARIO EXPLICATIVO FINAL ==========
print("\n" + "=" * 60)
print("üß† EXPLICACI√ìN DETALLADA:")
print("=" * 60)
print("""
DIFERENCIA CLAVE: ESTRUCTURA DE DATOS PARA CNN vs MLP

PARA CNN (Convolutional Neural Network):
------------------------------------------
  ‚Ä¢ Estructura: (32, 32, 3) - SE MANTIENE ‚úÖ
  ‚Ä¢ Las im√°genes conservan su estructura tridimensional
  ‚Ä¢ Dimensiones: [altura, ancho, canales]
  
  ¬øPor qu√© es importante?
  ‚Ä¢ Los filtros convolucionales recorren la imagen espacialmente
  ‚Ä¢ Detectan patrones locales: bordes, texturas, formas
  ‚Ä¢ Se aprovecha la relaci√≥n entre p√≠xeles vecinos
  ‚Ä¢ Jerarqu√≠a de features: bordes ‚Üí texturas ‚Üí formas ‚Üí objetos
  ‚Ä¢ Reducci√≥n progresiva de dimensionalidad con pooling
  ‚Ä¢ Mucho m√°s eficiente: menos par√°metros, mejor generalizaci√≥n
  
PARA MLP (Multi-Layer Perceptron):
-----------------------------------
  ‚Ä¢ Estructura: (3072,) - SE APLANAR√çA con flatten() ‚ùå
  ‚Ä¢ Se pierde COMPLETAMENTE la informaci√≥n espacial
  ‚Ä¢ Cada p√≠xel = feature independiente
  
  Problemas:
  ‚Ä¢ No se aprovechan patrones locales ni vecindad espacial
  ‚Ä¢ P√≠xel en (0,0) no tiene relaci√≥n con p√≠xel en (0,1)
  ‚Ä¢ Mayor n√∫mero de par√°metros (3072 √ó hidden_size)
  ‚Ä¢ Menos eficiente y m√°s propenso a overfitting
  ‚Ä¢ No es escalable a im√°genes grandes

EJEMPLO PR√ÅCTICO:
-----------------
Imagina detectar un "borde vertical":
  
  CNN: Un filtro 3x3 detecta el patr√≥n local
       [[-1,  0,  1],
        [-1,  0,  1],
        [-1,  0,  1]]
       ‚úÖ Eficiente: 9 par√°metros
  
  MLP: Necesitar√≠a aprender la relaci√≥n entre p√≠xeles
       sin estructura espacial
       ‚ùå Ineficiente: miles de par√°metros

‚ö†Ô∏è  REGLA DE ORO PARA CNN:
    ¬°NUNCA aplicar reshape() ni flatten() a los datos de entrada!
    Solo se aplana DESPU√âS de las capas convolucionales, 
    antes de las capas fully connected finales.
""")

print("\n" + "=" * 60)
print("‚úÖ ISSUE 5 COMPLETADO")
print("=" * 60)
print("\nResumen de verificaciones:")
print("  ‚úÖ Estructura 2D mantenida: (32, 32, 3)")
print("  ‚úÖ Dataset completo: (50000, 32, 32, 3)")
print("  ‚úÖ Sin flatten() ni reshape()")
print("  ‚úÖ 3 canales RGB preservados")
print("  ‚úÖ Imagen de ejemplo guardada")
print("  ‚úÖ Comparaci√≥n visual generada")
print("  ‚úÖ Listo para entrenar CNN")
print("=" * 60)