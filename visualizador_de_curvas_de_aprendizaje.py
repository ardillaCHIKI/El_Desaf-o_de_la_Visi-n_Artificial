# Issue 3(F3): VisualizaciÃ³n de Curvas de Aprendizaje
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

print("=" * 70)
print("ISSUE 3(F3): VISUALIZACIÃ“N DE CURVAS DE APRENDIZAJE")
print("=" * 70)

# ========== PREPARAR DATOS Y ENTRENAR (Resumen del issue anterior) ==========
print("\nğŸ“Š PASO 1: PREPARANDO DATOS Y ENTRENANDO MODELO")
print("=" * 70)

print("\nCargando y preparando CIFAR-10...")
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
print("âœ… Datos preparados")

print("\nConstruyendo modelo...")
model = Sequential([
    Input(shape=(32, 32, 3)),
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
], name="CNN_CIFAR10")

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print("âœ… Modelo compilado")

print("\nEntrenando modelo (esto puede tomar varios minutos)...")
history = model.fit(
    x_train, y_train,
    epochs=10,
    batch_size=64,
    validation_split=0.1,
    verbose=0  # Silencioso para no saturar la salida
)
print("âœ… Entrenamiento completado\n")

# ========== EXTRAER DATOS DEL HISTORIAL ==========
print("=" * 70)
print("ğŸ“ˆ PASO 2: EXTRAYENDO DATOS DEL HISTORIAL")
print("=" * 70)

# Extraer mÃ©tricas
train_acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
train_loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(1, len(train_acc) + 1)

print(f"\nDatos extraÃ­dos correctamente:")
print(f"  â€¢ NÃºmero de Ã©pocas: {len(train_acc)}")
print(f"  â€¢ MÃ©tricas disponibles: {list(history.history.keys())}")
print(f"\nÃšltima Ã©poca:")
print(f"  â€¢ Train Accuracy: {train_acc[-1]:.4f} ({train_acc[-1]*100:.2f}%)")
print(f"  â€¢ Val Accuracy:   {val_acc[-1]:.4f} ({val_acc[-1]*100:.2f}%)")
print(f"  â€¢ Train Loss:     {train_loss[-1]:.4f}")
print(f"  â€¢ Val Loss:       {val_loss[-1]:.4f}")

# ========== CREAR VISUALIZACIONES ==========
print("\n" + "=" * 70)
print("ğŸ“Š PASO 3: GENERANDO VISUALIZACIONES")
print("=" * 70)

# Configurar estilo general
plt.style.use('default')
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
fig.suptitle('Curvas de Aprendizaje - CNN en CIFAR-10', fontsize=16, fontweight='bold')

# ========== GRÃFICO 1: PRECISIÃ“N (ACCURACY) ==========
print("\nGenerando grÃ¡fico de PrecisiÃ³n...")

ax1.plot(epochs_range, train_acc, 'b-o', label='Entrenamiento', linewidth=2, markersize=6)
ax1.plot(epochs_range, val_acc, 'r-s', label='ValidaciÃ³n', linewidth=2, markersize=6)

ax1.set_xlabel('Ã‰poca', fontsize=12, fontweight='bold')
ax1.set_ylabel('PrecisiÃ³n (Accuracy)', fontsize=12, fontweight='bold')
ax1.set_title('PrecisiÃ³n: Entrenamiento vs ValidaciÃ³n', fontsize=13, fontweight='bold')
ax1.legend(loc='lower right', fontsize=11)
ax1.grid(True, alpha=0.3, linestyle='--')
ax1.set_xlim(1, len(train_acc))
ax1.set_ylim(0, 1)

# AÃ±adir anotaciones en puntos clave
max_val_acc_idx = np.argmax(val_acc)
ax1.annotate(f'Mejor: {val_acc[max_val_acc_idx]:.3f}',
             xy=(max_val_acc_idx + 1, val_acc[max_val_acc_idx]),
             xytext=(10, -15), textcoords='offset points',
             bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),
             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))

print("âœ… GrÃ¡fico de PrecisiÃ³n generado")

# ========== GRÃFICO 2: PÃ‰RDIDA (LOSS) ==========
print("Generando grÃ¡fico de PÃ©rdida...")

ax2.plot(epochs_range, train_loss, 'b-o', label='Entrenamiento', linewidth=2, markersize=6)
ax2.plot(epochs_range, val_loss, 'r-s', label='ValidaciÃ³n', linewidth=2, markersize=6)

ax2.set_xlabel('Ã‰poca', fontsize=12, fontweight='bold')
ax2.set_ylabel('PÃ©rdida (Loss)', fontsize=12, fontweight='bold')
ax2.set_title('PÃ©rdida: Entrenamiento vs ValidaciÃ³n', fontsize=13, fontweight='bold')
ax2.legend(loc='upper right', fontsize=11)
ax2.grid(True, alpha=0.3, linestyle='--')
ax2.set_xlim(1, len(train_loss))

# AÃ±adir anotaciones en puntos clave
min_val_loss_idx = np.argmin(val_loss)
ax2.annotate(f'MÃ­nimo: {val_loss[min_val_loss_idx]:.3f}',
             xy=(min_val_loss_idx + 1, val_loss[min_val_loss_idx]),
             xytext=(10, 15), textcoords='offset points',
             bbox=dict(boxstyle='round,pad=0.5', fc='lightgreen', alpha=0.7),
             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))

print("âœ… GrÃ¡fico de PÃ©rdida generado")

plt.tight_layout()
plt.savefig('curvas_aprendizaje.png', dpi=150, bbox_inches='tight')
print("\nâœ… GrÃ¡ficos guardados como 'curvas_aprendizaje.png'")
plt.show()

# ========== ANÃLISIS AUTOMÃTICO DEL COMPORTAMIENTO ==========
print("\n" + "=" * 70)
print("ğŸ” PASO 4: ANÃLISIS AUTOMÃTICO DEL COMPORTAMIENTO")
print("=" * 70)

# Calcular diferencias y tendencias
final_gap = train_acc[-1] - val_acc[-1]
loss_gap = val_loss[-1] - train_loss[-1]
val_acc_trend = val_acc[-1] - val_acc[-3] if len(val_acc) >= 3 else 0
val_loss_trend = val_loss[-1] - val_loss[-3] if len(val_loss) >= 3 else 0

print("\nğŸ“Š MÃ‰TRICAS CLAVE:\n")
print(f"Accuracy final:")
print(f"  â€¢ Entrenamiento: {train_acc[-1]:.4f} ({train_acc[-1]*100:.2f}%)")
print(f"  â€¢ ValidaciÃ³n:    {val_acc[-1]:.4f} ({val_acc[-1]*100:.2f}%)")
print(f"  â€¢ Diferencia:    {final_gap:.4f} ({final_gap*100:.2f}%)")

print(f"\nLoss final:")
print(f"  â€¢ Entrenamiento: {train_loss[-1]:.4f}")
print(f"  â€¢ ValidaciÃ³n:    {val_loss[-1]:.4f}")
print(f"  â€¢ Diferencia:    {loss_gap:.4f}")

print(f"\nTendencia (Ãºltimas 3 Ã©pocas):")
print(f"  â€¢ Val Accuracy: {'+' if val_acc_trend > 0 else ''}{val_acc_trend:.4f} {'â†‘' if val_acc_trend > 0 else 'â†“'}")
print(f"  â€¢ Val Loss:     {'+' if val_loss_trend > 0 else ''}{val_loss_trend:.4f} {'â†‘' if val_loss_trend > 0 else 'â†“'}")

# ========== DIAGNÃ“STICO DETALLADO ==========
print("\n" + "=" * 70)
print("ğŸ©º DIAGNÃ“STICO DETALLADO:")
print("=" * 70)

# ClasificaciÃ³n del comportamiento
print("\n" + "â”€" * 70)
print("ANÃLISIS DE OVERFITTING/UNDERFITTING:")
print("â”€" * 70)

# 1. AnÃ¡lisis de overfitting
print("\n1ï¸âƒ£  OVERFITTING (Sobreajuste):")
if final_gap > 0.15:
    overfitting_level = "ğŸ”´ ALTO"
    overfitting_desc = "El modelo memoriza datos de entrenamiento"
elif final_gap > 0.08:
    overfitting_level = "ğŸŸ¡ MODERADO"
    overfitting_desc = "Hay sobreajuste, pero controlable"
elif final_gap > 0.03:
    overfitting_level = "ğŸŸ¢ BAJO"
    overfitting_desc = "Overfitting mÃ­nimo, buen equilibrio"
else:
    overfitting_level = "âœ… NINGUNO"
    overfitting_desc = "Excelente generalizaciÃ³n"

print(f"   Nivel: {overfitting_level}")
print(f"   Gap de accuracy: {final_gap:.4f} ({final_gap*100:.2f}%)")
print(f"   InterpretaciÃ³n: {overfitting_desc}")

# 2. AnÃ¡lisis de underfitting
print("\n2ï¸âƒ£  UNDERFITTING (Subajuste):")
if train_acc[-1] < 0.5:
    underfitting_level = "ğŸ”´ ALTO"
    underfitting_desc = "El modelo no aprende bien los datos"
elif train_acc[-1] < 0.7:
    underfitting_level = "ğŸŸ¡ MODERADO"
    underfitting_desc = "El modelo podrÃ­a aprender mÃ¡s"
else:
    underfitting_level = "âœ… NINGUNO"
    underfitting_desc = "El modelo aprende adecuadamente"

print(f"   Nivel: {underfitting_level}")
print(f"   Train accuracy: {train_acc[-1]:.4f} ({train_acc[-1]*100:.2f}%)")
print(f"   InterpretaciÃ³n: {underfitting_desc}")

# 3. AnÃ¡lisis de convergencia
print("\n3ï¸âƒ£  CONVERGENCIA:")
if abs(val_acc_trend) < 0.005 and abs(val_loss_trend) < 0.01:
    convergence = "âœ… CONVERGIDA"
    convergence_desc = "Las mÃ©tricas se han estabilizado"
elif val_acc_trend > 0 and val_loss_trend < 0:
    convergence = "ğŸŸ¢ MEJORANDO"
    convergence_desc = "El modelo sigue aprendiendo"
elif val_acc_trend < 0 and val_loss_trend > 0:
    convergence = "ğŸ”´ EMPEORANDO"
    convergence_desc = "Posible overfitting progresivo"
else:
    convergence = "ğŸŸ¡ INESTABLE"
    convergence_desc = "Las mÃ©tricas fluctÃºan"

print(f"   Estado: {convergence}")
print(f"   InterpretaciÃ³n: {convergence_desc}")

# ========== INTERPRETACIÃ“N DETALLADA ==========
print("\n" + "=" * 70)
print("ğŸ“ INTERPRETACIÃ“N DETALLADA DE LAS CURVAS:")
print("=" * 70)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INTERPRETACIÃ“N DE LAS CURVAS DE APRENDIZAJE                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”µ CURVA DE ACCURACY (PrecisiÃ³n):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")

# AnÃ¡lisis especÃ­fico de accuracy
if train_acc[-1] > val_acc[-1]:
    print("""âœ“ La curva de ENTRENAMIENTO estÃ¡ por ENCIMA de VALIDACIÃ“N
  â†’ Esto es NORMAL y esperado
  â†’ El modelo ve los datos de entrenamiento durante el aprendizaje
  â†’ La validaciÃ³n es "nueva" para el modelo en cada Ã©poca""")
else:
    print("""âš ï¸  La curva de VALIDACIÃ“N estÃ¡ por ENCIMA de ENTRENAMIENTO
  â†’ Esto es INUSUAL (pero puede pasar con validaciÃ³n pequeÃ±a)
  â†’ Posible fluctuaciÃ³n aleatoria
  â†’ O el conjunto de validaciÃ³n es mÃ¡s "fÃ¡cil""")

if val_acc_trend > 0:
    print("""
âœ“ La accuracy de validaciÃ³n SIGUE SUBIENDO
  â†’ El modelo todavÃ­a estÃ¡ aprendiendo
  â†’ PodrÃ­amos entrenar mÃ¡s Ã©pocas
  â†’ No hay seÃ±ales fuertes de overfitting""")
elif val_acc_trend < -0.01:
    print("""
âš ï¸  La accuracy de validaciÃ³n estÃ¡ BAJANDO
  â†’ SeÃ±al clara de OVERFITTING
  â†’ El modelo empieza a memorizar en lugar de generalizar
  â†’ DeberÃ­amos haber parado antes (early stopping)""")
else:
    print("""
âœ“ La accuracy de validaciÃ³n se ha ESTABILIZADO
  â†’ El modelo ha alcanzado su capacidad de aprendizaje
  â†’ Entrenar mÃ¡s Ã©pocas probablemente no ayude mucho""")

print("""
ğŸ”´ CURVA DE LOSS (PÃ©rdida):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")

# AnÃ¡lisis especÃ­fico de loss
if val_loss[-1] > train_loss[-1]:
    gap_description = "moderada" if loss_gap < 0.3 else "grande"
    print(f"""âœ“ La loss de VALIDACIÃ“N es mayor que la de ENTRENAMIENTO
  â†’ Diferencia {gap_description}: {loss_gap:.3f}
  â†’ Esto es normal (el modelo optimiza train loss)""")
    
    if loss_gap > 0.5:
        print("""  âš ï¸  La diferencia es MUY GRANDE
  â†’ SeÃ±al fuerte de OVERFITTING
  â†’ Considerar: Dropout, regularizaciÃ³n L2, mÃ¡s datos""")

if val_loss_trend < 0:
    print("""
âœ“ La loss de validaciÃ³n SIGUE BAJANDO
  â†’ El modelo estÃ¡ mejorando
  â†’ AÃºn hay margen para entrenar mÃ¡s""")
elif val_loss_trend > 0.05:
    print("""
âš ï¸  La loss de validaciÃ³n estÃ¡ SUBIENDO
  â†’ OVERFITTING en progreso
  â†’ El modelo empieza a memorizar patrones especÃ­ficos
  â†’ Momento ideal para DETENER el entrenamiento""")
else:
    print("""
âœ“ La loss de validaciÃ³n se mantiene ESTABLE
  â†’ El modelo ha alcanzado su Ã³ptimo
  â†’ MÃ¡s entrenamiento no mejorarÃ¡ significativamente""")

# ========== PATRONES COMUNES ==========
print("\n" + "=" * 70)
print("ğŸ“š PATRONES COMUNES EN CURVAS DE APRENDIZAJE:")
print("=" * 70)

print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PATRÃ“N 1: MODELO IDEAL                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Train Accuracy: â†—â†—â†— â†’ Sube constantemente                     â”‚
â”‚ Val Accuracy:   â†—â†—â†’ â†’ Sube y se estabiliza cerca del train    â”‚
â”‚ Gap:            PequeÃ±o (< 5%)                                 â”‚
â”‚                                                                â”‚
â”‚ InterpretaciÃ³n: âœ… Modelo generaliza bien                      â”‚
â”‚ AcciÃ³n: Ninguna, Â¡estÃ¡ perfecto!                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PATRÃ“N 2: OVERFITTING (Sobreajuste)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Train Accuracy: â†—â†—â†— â†’ Sigue subiendo                          â”‚
â”‚ Val Accuracy:   â†—â†’â†˜ â†’ Sube, se estabiliza, BAJA              â”‚
â”‚ Gap:            Grande y creciente (> 10%)                     â”‚
â”‚                                                                â”‚
â”‚ InterpretaciÃ³n: ğŸ”´ El modelo MEMORIZA en vez de aprender      â”‚
â”‚ AcciÃ³n:                                                        â”‚
â”‚   â€¢ Early stopping (parar antes)                              â”‚
â”‚   â€¢ AÃ±adir Dropout                                            â”‚
â”‚   â€¢ RegularizaciÃ³n L2                                         â”‚
â”‚   â€¢ MÃ¡s datos de entrenamiento                                â”‚
â”‚   â€¢ Data augmentation                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PATRÃ“N 3: UNDERFITTING (Subajuste)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Train Accuracy: â†—â†’ â†’ Sube poco y se estanca BAJO             â”‚
â”‚ Val Accuracy:   â†—â†’ â†’ Similar al train, tambiÃ©n BAJO           â”‚
â”‚ Gap:            Muy pequeÃ±o, pero ambas bajas (< 60%)         â”‚
â”‚                                                                â”‚
â”‚ InterpretaciÃ³n: ğŸ”´ El modelo NO tiene capacidad suficiente    â”‚
â”‚ AcciÃ³n:                                                        â”‚
â”‚   â€¢ Modelo mÃ¡s grande (mÃ¡s filtros/capas)                     â”‚
â”‚   â€¢ Entrenar mÃ¡s Ã©pocas                                       â”‚
â”‚   â€¢ Learning rate mÃ¡s alto                                    â”‚
â”‚   â€¢ Reducir regularizaciÃ³n                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PATRÃ“N 4: MODELO EN PROGRESO                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Train Accuracy: â†—â†—â†— â†’ Subiendo consistentemente              â”‚
â”‚ Val Accuracy:   â†—â†—â†— â†’ Subiendo tambiÃ©n                       â”‚
â”‚ Gap:            Moderado (5-8%)                                â”‚
â”‚                                                                â”‚
â”‚ InterpretaciÃ³n: ğŸŸ¢ El modelo AÃšN estÃ¡ aprendiendo             â”‚
â”‚ AcciÃ³n:                                                        â”‚
â”‚   â€¢ Entrenar MÃS Ã©pocas                                       â”‚
â”‚   â€¢ Monitorear para detectar overfitting futuro               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
""")

# ========== DIAGNÃ“STICO ESPECÃFICO DE NUESTRO MODELO ==========
print("\n" + "=" * 70)
print("ğŸ¯ DIAGNÃ“STICO ESPECÃFICO DE NUESTRO MODELO:")
print("=" * 70)

# Determinar el patrÃ³n que mejor describe nuestro modelo
if final_gap < 0.05 and train_acc[-1] > 0.7:
    pattern = "âœ… PATRÃ“N 1: MODELO IDEAL"
    recommendation = "El modelo estÃ¡ bien equilibrado. No se necesitan cambios importantes."
elif final_gap > 0.10 or (val_acc_trend < -0.01 and val_loss_trend > 0.05):
    pattern = "âš ï¸  PATRÃ“N 2: OVERFITTING"
    recommendation = """
    Acciones recomendadas:
    â€¢ AÃ±adir Dropout(0.3) despuÃ©s de las capas Dense
    â€¢ Reducir nÃºmero de Ã©pocas o usar Early Stopping
    â€¢ Implementar Data Augmentation
    â€¢ AÃ±adir regularizaciÃ³n L2: Dense(64, kernel_regularizer='l2')
    """
elif train_acc[-1] < 0.6 and final_gap < 0.05:
    pattern = "âš ï¸  PATRÃ“N 3: UNDERFITTING"
    recommendation = """
    Acciones recomendadas:
    â€¢ Aumentar capacidad: mÃ¡s filtros (Conv2D(64, 128, 256))
    â€¢ AÃ±adir mÃ¡s capas convolucionales
    â€¢ Entrenar mÃ¡s Ã©pocas (20-30)
    â€¢ Aumentar learning rate: Adam(learning_rate=0.01)
    """
elif val_acc_trend > 0.01:
    pattern = "ğŸŸ¢ PATRÃ“N 4: MODELO EN PROGRESO"
    recommendation = """
    Acciones recomendadas:
    â€¢ Entrenar mÃ¡s Ã©pocas (15-20 total)
    â€¢ Monitorear para detectar cuando empiece overfitting
    â€¢ Implementar Early Stopping con patience=3
    """
else:
    pattern = "ğŸŸ¡ PATRÃ“N MIXTO"
    recommendation = "El modelo muestra caracterÃ­sticas mixtas. Analizar mÃ¡s Ã©pocas."

print(f"\nPATRÃ“N IDENTIFICADO: {pattern}")
print("\nRECOMENDACIONES:")
print(recommendation)

# ========== RESUMEN EJECUTIVO ==========
print("\n" + "=" * 70)
print("ğŸ“‹ RESUMEN EJECUTIVO:")
print("=" * 70)

print(f"""
RESULTADOS FINALES:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Train Accuracy: {train_acc[-1]*100:.2f}%
â€¢ Val Accuracy:   {val_acc[-1]*100:.2f}%
â€¢ Gap:            {final_gap*100:.2f}%

ESTADO DEL MODELO:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Overfitting:  {overfitting_level}
â€¢ Underfitting: {underfitting_level}
â€¢ Convergencia: {convergence}

PATRÃ“N: {pattern}

GRÃFICOS GENERADOS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Curva de PrecisiÃ³n (Accuracy)
âœ… Curva de PÃ©rdida (Loss)
âœ… Guardados en 'curvas_aprendizaje.png'

PRÃ“XIMOS PASOS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Evaluar en test set (datos nunca vistos)
2. Analizar matriz de confusiÃ³n
3. Visualizar predicciones individuales
4. Si es necesario, ajustar segÃºn recomendaciones
""")

print("\n" + "=" * 70)
print("ISSUE 3(F3) COMPLETADO âœ…")
print("=" * 70)
print("\nğŸ“Š GrÃ¡ficos generados y anÃ¡lisis completo")
print("ğŸ” Comportamiento del modelo interpretado")
print("ğŸ’¡ Recomendaciones especÃ­ficas proporcionadas")